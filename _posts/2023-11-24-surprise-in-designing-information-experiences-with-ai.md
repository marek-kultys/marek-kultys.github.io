---
layout: blog-post
label: blog-post
title: Surprise in Designing Information Experiences with AI
date: November 2023
image:
link:
excerpt_separator: <!--more-->
published: false
---

<i>Our AI model serves us a prediction sandwich: 30 interesting hypotheses stuck between a pile at the top that is super-obvious the rest at the bottom that makes no sense at all...<i>

This quote from a user interview has stuck with me for years. I heard it from a drug discoverer at BenevolentAI when we discussed their strategies for effective triage of a list of 200 drug target predictions generated by an AI model.

Their approach was to:
1. Skim through the first two dozens of top-ranked predictions to get a sense of how relevant the whole list is. Finding expected, highly-published, obvious targets was a reassuring sign that the rest of the list was related the desired area of biology.
2. Jump to results ranked between 20-60 and invest most of triage time there. In the layer below the obvious, results tended to be more varied, sometimes a little unexpected and sometimes outright surprising. Time was spent to investigate each prediction to understand the scientific rationale for prediction in hopes to find a golden nugget — a novel drug target hypothesis.
3. Scan the targets ranked 70 or 80 and below to rescue anything of value. This third layer of predictions used to include too much noise and not enough relevance to justify any significant effort.

The quote perfectly captures the opportunities and the challenges in designing information experiences with generative technologies, such as AI. From the perspective of an information consumer (i.e. model user), it's all about balancing between value and noise. Or, as in the specific case of drug target triage, it's about navigating between the obvious, the surprising, and the nonsensical.

How do we design AI-driven information experiences that .



<b>Information Experiences<b>

First, let's define what we mean by information experiences.

These are interfaces where the user's primary job is to consume information – think data-heavy, information-rich tools like User Analytics, Google Maps, or Genome Browsers. As designers, while we typically don't produce the content, we shape how users interact with and consume it.





<b>The Spectrum of Surprise<b>

Surprise emerges as one of the crucial factors we can control in these experiences. I've observed a clear pattern in how surprise operates across AI-powered information systems:

![Image](/img/posts/24-11-2023/zones-of-surprise.png)

Zero Surprise: The "I Know This" Zone
When a system shows us information we already know (like an AI recommending a Wikipedia-level fact), the surprise factor is zero. While safe, these interactions offer limited value.

Medium Surprise: The "Justify" Zone
This is where things get interesting. The system presents information that's new to the user but can be validated through existing knowledge or resources. Users might think, "Ah, I hadn't considered that, but it makes sense." This zone often leads to the most productive interactions.

Maximum Surprise: The "Trust Required" Zone
Here, the system presents truly novel information that requires a leap of faith. Users can't immediately validate the information through existing knowledge or resources. This zone offers the highest potential rewards but also carries the greatest risks.





<h3>The Risk-Reward Balance</h3>

As surprise increases, both potential rewards and risks grow proportionally. A highly surprising recommendation could lead to a breakthrough discovery, but it might also lead to wasted time if the information proves unreliable.
Different users have different comfort zones for surprise:

![Image](/img/posts/24-11-2023/risk-reward.png)

Some users, like safety profilers, have a low tolerance for surprise and risk
Others, like research biologists seeking novel pathways, actively seek surprise




<h3>Real-World Examples</h3>

Clinical Trial Site Selection

In my current role leading design for Merlin, we help teams optimize clinical study design. When recommending trial sites and countries, we carefully manage surprise across different zones:
In the "I Know This" zone, we have recommendations like the USA – obvious choices backed by extensive historical data and familiar regulatory environments. While safe, these offer limited competitive advantage.

Moving into the "Justify" zone, we suggest less obvious locations like Austria or Taiwan. These recommendations carry higher surprise value but remain verifiable through historical recruitment rates, startup time metrics, and previous study data. The risk is manageable because all data points are traceable, while the reward – less competition for patient recruitment – can be significant.


AI Art Generation

A recent experiment with Midjourney illustrated the power of managed surprise. I prompted it to combine two distant concepts: WiFi and the early Renaissance painter Giotto. This was a high-surprise scenario with minimal risk, as the goal was artistic exploration.

The result was surprisingly coherent – maintaining Giotto's style while cleverly representing internet connectivity through connected portrait bubbles. This high-surprise outcome worked because users could trace the logic of how different elements came together. The surprise felt earned rather than random.


Target Identification in Drug Discovery

Remember the user quote I opened with? "The results are a bit like a sandwich: 50 interesting hypotheses stuck between 30 obvious hits at the top and the nonsense rest at the bottom." This perfectly describes the challenge we faced at BAI when designing tools for scientists exploring gene targets.
Users approached these tools with two distinct goals:

Consolidating information from multiple sources (low surprise appetite)
Finding inspiration for new research directions (high surprise appetite)

The key to success was building trust across the surprise spectrum. We started with known relationships – the "obvious hits at the top" – to establish baseline confidence. Then, in the middle layer of the "sandwich," we presented those "50 interesting hypotheses" – less obvious connections that scientists could verify through multiple paths:

Evidence categorized by type
Links to external databases
Supporting literature
Lab validation data

This multi-modal verification system was crucial for helping scientists navigate through surprising recommendations. When users discovered genuinely novel biological relationships and validated them in the lab, it created what we called "bingo moments" – high-risk, high-reward discoveries that built trust for future explorations.

The "nonsense rest at the bottom" served as a reminder of why managing surprise is so crucial. Without proper verification tools and supporting evidence, potentially valuable insights could be lost in the noise of low-quality recommendations.
Designing for Surprise



As designers of AI-powered information experiences, we're not just information architects – we're surprise managers. This requires:

Understanding your users' comfort zones for surprise
Providing appropriate verification tools and supporting evidence
Building trust gradually through consistent delivery at lower surprise levels
Creating clear paths for users to investigate and validate surprising recommendations

The next time you design an information experience, consider where on the surprise spectrum your users need to operate, and build the supporting infrastructure to help them navigate that space confidently.








<div class="block-margin media-wrapper">
   xxx
</div>

<!--more-->

[xxx](xxx)
